[2024-10-28T04:03:54.986+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:03:54.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:03:55.006+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:03:54.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:03:59.157+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:04:00.599+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.579+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:postgres_to_mysql_etl
[2024-10-28T04:04:00.622+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.621+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:postgres_to_mysql_etl
[2024-10-28T04:04:00.639+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.639+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:postgres_to_mysql_etl
[2024-10-28T04:04:00.664+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.663+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:postgres_to_mysql_etl
[2024-10-28T04:04:00.692+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.692+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:postgres_to_mysql_etl
[2024-10-28T04:04:00.720+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.720+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:postgres_to_mysql_etl
[2024-10-28T04:04:00.745+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.744+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:postgres_to_mysql_etl
[2024-10-28T04:04:00.748+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:04:00.774+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.773+0000] {dag.py:3262} INFO - Creating ORM DAG for postgres_to_mysql_etl
[2024-10-28T04:04:00.791+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:00.790+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:04:00.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 5.936 seconds
[2024-10-28T04:04:31.690+0000] {processor.py:186} INFO - Started process (PID=514) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:04:31.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:04:31.698+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:31.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:04:32.227+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:04:32.281+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:32.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:04:32.312+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:04:32.312+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:04:32.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.947 seconds
[2024-10-28T04:05:03.321+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:03.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:05:03.329+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:03.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:04.235+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:04.682+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:04.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:05:04.735+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:04.735+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:05:04.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.485 seconds
[2024-10-28T04:05:35.254+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:35.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:05:35.269+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:35.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:36.243+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:05:37.239+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:37.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:05:37.295+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:05:37.295+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:05:37.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.118 seconds
[2024-10-28T04:06:47.095+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:06:47.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:06:47.098+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:06:47.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:06:50.135+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:06:52.461+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:06:52.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:06:52.540+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:06:52.540+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:06:52.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 5.688 seconds
[2024-10-28T04:08:41.485+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:08:43.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:08:46.956+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:08:44.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:09:30.164+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:09:28.888+0000] {timeout.py:68} ERROR - Process timed out, PID: 552
[2024-10-28T04:10:27.247+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:09:30.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 52, in <module>
    from .abstracts import CMySQLPrepStmt, MySQLConnectionAbstract
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 72, in <module>
    from .constants import (
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/constants.py", line 37, in <module>
    from .errors import ProgrammingError
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1124, in get_code
  File "<frozen importlib._bootstrap_external>", line 753, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 552
[2024-10-28T04:10:32.595+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:11:05.299+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T04:14:55.489+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:15:01.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:15:13.196+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:15:06.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:16:37.747+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:15:57.435+0000] {timeout.py:68} ERROR - Process timed out, PID: 554
[2024-10-28T04:20:21.609+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:16:57.449+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 52, in <module>
    from .abstracts import CMySQLPrepStmt, MySQLConnectionAbstract
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 72, in <module>
    from .constants import (
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/constants.py", line 37, in <module>
    from .errors import ProgrammingError
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1087, in get_code
  File "<frozen importlib._bootstrap_external>", line 1187, in get_data
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 554
[2024-10-28T04:20:54.275+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:31:33.401+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:31:33.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:31:33.414+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:31:33.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:31:36.534+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:31:37.286+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:31:37.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:31:38.249+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:31:38.248+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:31:38.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.985 seconds
[2024-10-28T04:32:08.873+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:08.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:32:08.911+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:08.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:11.261+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:11.327+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:11.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:32:11.384+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:11.383+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:32:11.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.572 seconds
[2024-10-28T04:32:41.864+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:41.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:32:41.902+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:41.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:43.373+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:32:43.404+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:43.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:32:43.438+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:32:43.438+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:32:43.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.651 seconds
[2024-10-28T04:33:13.617+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:13.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:33:13.622+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:13.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:14.905+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:14.934+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:14.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:33:14.966+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:14.966+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:33:15.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.759 seconds
[2024-10-28T04:33:45.926+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:45.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:33:45.968+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:45.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:47.358+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:33:47.405+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:47.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:33:47.440+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:33:47.440+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:33:47.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.657 seconds
[2024-10-28T04:34:17.743+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:17.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:34:17.748+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:17.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:18.538+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:18.600+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:18.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:34:18.703+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:18.699+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:34:18.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.037 seconds
[2024-10-28T04:34:49.316+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:49.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:34:49.327+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:49.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:49.787+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:34:49.817+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:49.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:34:49.858+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:34:49.858+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:34:49.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.603 seconds
[2024-10-28T04:35:20.579+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:20.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:35:20.586+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:20.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:21.061+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:21.092+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:21.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:35:21.128+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:21.128+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:35:21.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.609 seconds
[2024-10-28T04:35:51.503+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:51.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:35:51.532+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:51.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:51.870+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:35:51.917+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:51.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:35:51.959+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:35:51.959+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:35:52.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.620 seconds
[2024-10-28T04:36:22.305+0000] {processor.py:186} INFO - Started process (PID=127) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:22.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:36:22.315+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:22.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:22.843+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:22.907+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:22.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:36:22.972+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:22.971+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:36:23.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.725 seconds
[2024-10-28T04:36:53.107+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:53.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:36:53.114+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:53.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:53.708+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:36:53.781+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:53.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:36:53.841+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:36:53.840+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:36:53.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.832 seconds
[2024-10-28T04:37:24.692+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:37:24.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:37:24.697+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:37:24.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:37:25.052+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:37:25.096+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:37:25.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:37:25.147+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:37:25.146+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:37:25.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.506 seconds
[2024-10-28T04:41:23.237+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:41:23.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:41:23.246+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:41:23.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:41:25.136+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:41:25.356+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:41:25.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:41:25.776+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:41:25.775+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:41:25.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.646 seconds
[2024-10-28T04:41:56.785+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:41:56.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:41:56.802+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:41:56.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:42:00.340+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:42:00.467+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:42:00.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:42:00.540+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:42:00.539+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:42:00.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.857 seconds
[2024-10-28T04:42:31.542+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:42:31.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:42:31.549+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:42:31.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:42:33.798+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:42:33.875+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:42:33.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:42:33.917+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:42:33.916+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:42:34.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.590 seconds
[2024-10-28T04:43:05.155+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:05.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:43:05.289+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:05.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:08.964+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:09.057+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:09.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:43:09.175+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:09.174+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:43:09.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.210 seconds
[2024-10-28T04:43:40.276+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:40.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:43:40.314+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:40.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:41.379+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:43:41.429+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:41.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:43:41.561+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:43:41.560+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:43:41.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.612 seconds
[2024-10-28T04:44:12.156+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:12.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:44:12.164+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:12.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:12.660+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:12.694+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:12.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:44:12.725+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:12.725+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-27 00:00:00+00:00, run_after=2024-10-28 00:00:00+00:00
[2024-10-28T04:44:12.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.816 seconds
[2024-10-28T04:44:43.606+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:43.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:44:43.624+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:43.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:44.708+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:44:44.753+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:44.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:44:44.816+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:44:44.815+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:44:44.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.263 seconds
[2024-10-28T04:45:15.287+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:15.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:45:15.299+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:15.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:18.065+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:18.391+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:18.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:45:18.509+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:18.508+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:45:18.653+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.376 seconds
[2024-10-28T04:45:48.962+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:48.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:45:48.968+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:48.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:50.670+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:45:50.710+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:50.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:45:50.766+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:45:50.766+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:45:50.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.864 seconds
[2024-10-28T04:46:21.901+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:46:21.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:46:21.945+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:46:21.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:46:49.181+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:46:52.111+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:46:52.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:46:52.285+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:46:52.284+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:46:52.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 30.632 seconds
[2024-10-28T04:47:50.079+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:47:50.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:47:50.090+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:47:50.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:47:51.645+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:47:51.720+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:47:51.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:47:51.796+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:47:51.796+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:47:51.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.800 seconds
[2024-10-28T04:48:22.307+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:22.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:48:22.327+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:22.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:25.065+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:25.128+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:25.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:48:25.193+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:25.193+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:48:25.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.974 seconds
[2024-10-28T04:48:55.964+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:55.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:48:55.971+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:55.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:57.314+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:48:57.402+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:57.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:48:57.439+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:48:57.439+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:48:57.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.521 seconds
[2024-10-28T04:49:28.153+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:49:28.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:49:28.160+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:49:28.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:49:29.378+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:49:29.462+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:49:29.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:49:29.549+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:49:29.543+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:49:29.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.465 seconds
[2024-10-28T04:50:00.252+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:00.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:50:00.260+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:00.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:01.799+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:02.540+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:02.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:50:02.654+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:02.654+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:50:02.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.488 seconds
[2024-10-28T04:50:33.220+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:33.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:50:33.232+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:33.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:35.220+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:50:35.365+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:35.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:50:35.463+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:50:35.463+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:50:35.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.370 seconds
[2024-10-28T04:51:06.230+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:06.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:51:06.237+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:06.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:11.172+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:14.890+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:14.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:51:15.025+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:15.024+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:51:15.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 8.916 seconds
[2024-10-28T04:51:45.461+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:45.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:51:45.509+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:45.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:47.147+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:51:47.259+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:47.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:51:47.346+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:51:47.346+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:51:47.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.958 seconds
[2024-10-28T04:52:17.647+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:52:17.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:52:17.653+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:52:17.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:52:18.868+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:52:18.907+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:52:18.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:52:18.950+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:52:18.949+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:52:19.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.489 seconds
[2024-10-28T04:52:50.159+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:52:50.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:52:50.204+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:52:50.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:52:59.261+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:53:02.451+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:53:02.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:53:02.627+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:53:02.627+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:53:02.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 12.812 seconds
[2024-10-28T04:53:34.486+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:53:34.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:53:34.600+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:53:34.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:54:01.419+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:54:04.647+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:54:04.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:54:04.912+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:54:04.901+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:54:05.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 30.813 seconds
[2024-10-28T04:54:35.665+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:54:35.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:54:35.708+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:54:35.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:54:41.587+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:54:41.682+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:54:41.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:54:41.774+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:54:41.774+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:54:41.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 6.275 seconds
[2024-10-28T04:55:12.424+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:12.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:55:12.438+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:12.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:14.243+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:14.432+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:14.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:55:14.490+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:14.490+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:55:14.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.209 seconds
[2024-10-28T04:55:45.573+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:45.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:55:45.618+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:45.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:48.799+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:55:49.440+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:49.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:55:49.532+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:55:49.532+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:55:49.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.091 seconds
[2024-10-28T04:56:20.396+0000] {processor.py:186} INFO - Started process (PID=169) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:56:20.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:56:20.435+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:56:20.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:56:24.313+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:56:43.327+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:56:43.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:56:43.406+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:56:43.406+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:56:43.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 23.116 seconds
[2024-10-28T04:57:13.571+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:57:13.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:57:13.577+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:57:13.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:57:15.392+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T04:57:15.455+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:57:15.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T04:57:15.502+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:57:15.501+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T04:57:15.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.985 seconds
[2024-10-28T04:57:46.379+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T04:57:46.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T04:57:46.500+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:57:46.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T04:58:24.644+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:58:21.912+0000] {timeout.py:68} ERROR - Process timed out, PID: 190
[2024-10-28T05:02:20.461+0000] {logging_mixin.py:190} INFO - [2024-10-28T04:58:30.550+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 52, in <module>
    from .abstracts import CMySQLPrepStmt, MySQLConnectionAbstract
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 92, in <module>
    from .opentelemetry.constants import (
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/opentelemetry/constants.py", line 36, in <module>
    from opentelemetry import trace  # check api
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/trace/__init__.py", line 86, in <module>
    from opentelemetry import context as context_api
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/context/__init__.py", line 23, in <module>
    from opentelemetry.util._importlib_metadata import entry_points
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/util/_importlib_metadata.py", line 17, in <module>
    from importlib_metadata import (  # type: ignore
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1322, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1262, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1528, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1502, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1620, in find_spec
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 190
[2024-10-28T05:02:40.057+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:03:03.729+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:11:08.457+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:11:08.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:11:08.480+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:11:08.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:11:18.490+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:11:21.535+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:11:21.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:11:22.021+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:11:22.021+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:11:22.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 13.920 seconds
[2024-10-28T05:14:06.356+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:06.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:14:06.379+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:06.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:09.801+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:10.956+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:10.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:14:11.548+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:11.542+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:14:11.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 5.301 seconds
[2024-10-28T05:14:42.370+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:42.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:14:42.798+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:42.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:45.473+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:14:45.561+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:45.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:14:45.697+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:14:45.696+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:14:45.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.535 seconds
[2024-10-28T05:15:16.437+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:16.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:15:16.444+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:16.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:18.468+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:18.515+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:18.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:15:18.554+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:18.553+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:15:18.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.277 seconds
[2024-10-28T05:15:49.046+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:49.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:15:49.055+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:49.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:50.920+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:15:50.966+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:50.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:15:51.017+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:15:51.017+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:15:51.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.036 seconds
[2024-10-28T05:16:21.924+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:21.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:16:21.930+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:21.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:22.436+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:22.470+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:22.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:16:22.518+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:22.518+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:16:22.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.679 seconds
[2024-10-28T05:16:52.902+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:52.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:16:52.921+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:52.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:55.815+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:16:55.924+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:55.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:16:55.977+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:16:55.976+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:16:56.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.165 seconds
[2024-10-28T05:17:26.924+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:26.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:17:26.932+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:26.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:27.703+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:27.737+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:27.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:17:27.771+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:27.770+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:17:27.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.903 seconds
[2024-10-28T05:17:58.362+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:58.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:17:58.368+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:58.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:59.258+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:17:59.299+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:59.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:17:59.357+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:17:59.357+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:17:59.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.055 seconds
[2024-10-28T05:18:30.124+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:18:30.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:18:30.134+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:18:30.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:18:31.225+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:18:31.300+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:18:31.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:18:31.348+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:18:31.347+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:18:31.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.282 seconds
[2024-10-28T05:19:01.885+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:01.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:19:01.890+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:01.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:02.838+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:02.891+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:02.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:19:02.935+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:02.934+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:19:02.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.103 seconds
[2024-10-28T05:19:33.234+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:33.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:19:33.239+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:33.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:33.957+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:19:34.002+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:34.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:19:34.049+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:19:34.049+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:19:34.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.870 seconds
[2024-10-28T05:20:04.699+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:04.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:20:04.711+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:04.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:07.573+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:07.695+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:07.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:20:07.819+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:07.818+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:20:07.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.248 seconds
[2024-10-28T05:20:39.071+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:39.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:20:39.079+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:39.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:40.831+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:20:40.888+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:40.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:20:41.052+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:20:41.051+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:20:41.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.035 seconds
[2024-10-28T05:21:11.756+0000] {processor.py:186} INFO - Started process (PID=167) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:11.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:21:11.761+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:11.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:14.361+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:14.983+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:14.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:21:15.033+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:15.033+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:21:15.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.345 seconds
[2024-10-28T05:21:46.183+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:46.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:21:46.191+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:46.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:48.463+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:21:48.548+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:48.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:21:48.621+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:21:48.620+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:21:48.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.520 seconds
[2024-10-28T05:22:19.769+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:22:19.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:22:19.786+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:22:19.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:22:22.623+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:22:22.661+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:22:22.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:22:22.711+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:22:22.711+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:22:22.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.043 seconds
[2024-10-28T05:22:53.383+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:22:53.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:22:53.400+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:22:53.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:23:02.114+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:23:57.836+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:25:33.181+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:25:33.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:25:33.195+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:25:33.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:25:37.491+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:25:37.780+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:25:37.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:25:37.867+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:25:37.866+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:25:37.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.813 seconds
[2024-10-28T05:26:08.992+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:26:09.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:26:09.042+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:26:09.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:26:10.529+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:26:10.608+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:26:10.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:26:10.687+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:26:10.686+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:26:10.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.797 seconds
[2024-10-28T05:26:41.470+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:26:41.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:26:41.474+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:26:41.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:26:43.395+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:27:15.538+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:27:47.166+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:27:47.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:27:47.226+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:27:47.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:27:56.680+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:28:28.131+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:28:28.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:28:28.174+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:28:28.174+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:28:28.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 41.167 seconds
[2024-10-28T05:28:59.814+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:28:59.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:28:59.832+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:28:59.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:29:13.751+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:29:21.416+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:29:21.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:29:21.611+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:29:21.611+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:29:21.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 21.937 seconds
[2024-10-28T05:29:51.980+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:29:51.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:29:51.986+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:29:51.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:29:54.124+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:29:54.201+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:29:54.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:29:54.266+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:29:54.266+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:29:54.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.387 seconds
[2024-10-28T05:30:25.365+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:25.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:30:25.374+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:25.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:26.097+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:26.245+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:26.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:30:26.289+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:26.289+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:30:26.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.011 seconds
[2024-10-28T05:30:56.678+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:56.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:30:56.686+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:56.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:57.229+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:30:57.370+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:57.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:30:57.412+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:30:57.412+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:30:57.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.843 seconds
[2024-10-28T05:31:27.721+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:27.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:31:27.726+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:27.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:28.078+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:28.131+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:28.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:31:28.181+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:28.180+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:31:28.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.518 seconds
[2024-10-28T05:31:58.788+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:58.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:31:58.793+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:58.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:59.089+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:31:59.123+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:59.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:31:59.162+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:31:59.161+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:31:59.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.423 seconds
[2024-10-28T05:32:29.903+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:32:29.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:32:29.907+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:32:29.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:32:30.243+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:32:30.287+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:32:30.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:32:30.330+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:32:30.329+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:32:30.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.474 seconds
[2024-10-28T05:33:00.615+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:00.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:33:00.619+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:00.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:01.170+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:01.216+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:01.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:33:01.261+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:01.260+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:33:01.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.692 seconds
[2024-10-28T05:33:32.218+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:32.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:33:32.223+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:32.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:33.158+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:33:33.468+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:33.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:33:33.543+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:33:33.542+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:33:33.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.428 seconds
[2024-10-28T05:34:04.034+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:04.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:34:04.041+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:04.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:04.521+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:04.568+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:04.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:34:04.621+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:04.621+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:34:04.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.647 seconds
[2024-10-28T05:34:34.790+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:34.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:34:34.795+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:34.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:35.145+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:34:35.180+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:35.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:34:35.218+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:34:35.218+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:34:35.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.472 seconds
[2024-10-28T05:35:06.212+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:35:06.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:35:06.218+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:35:06.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:35:08.453+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:35:08.746+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:35:08.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:35:08.837+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:35:08.836+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:35:08.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.708 seconds
[2024-10-28T05:35:39.317+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:35:39.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:35:39.368+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:35:39.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:35:53.582+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:37:30.608+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:37:30.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:37:30.632+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:37:30.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:37:34.855+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:38:06.372+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:38:44.642+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:38:44.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:38:44.648+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:38:44.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:38:46.632+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:39:18.818+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:39:55.650+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:39:55.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:39:55.662+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:39:55.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:39:56.884+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:39:59.791+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:39:59.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:39:59.997+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:39:59.996+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:40:00.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.532 seconds
[2024-10-28T05:40:55.042+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:40:55.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:40:55.061+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:40:55.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:41:51.332+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:41:41.406+0000] {timeout.py:68} ERROR - Process timed out, PID: 379
[2024-10-28T05:42:43.809+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:42:10.929+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1087, in get_code
  File "<frozen importlib._bootstrap_external>", line 1186, in get_data
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 379
[2024-10-28T05:43:14.818+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:44:06.927+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:44:06.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:44:06.931+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:44:06.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:44:11.043+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:44:43.784+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:45:34.618+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:45:34.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:45:34.625+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:45:34.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:45:36.550+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:45:37.333+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:45:37.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:45:37.409+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:45:37.409+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:45:37.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.958 seconds
[2024-10-28T05:46:08.249+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:08.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:46:08.263+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:08.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:09.890+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:09.972+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:09.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:46:10.093+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:10.092+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:46:10.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.980 seconds
[2024-10-28T05:46:40.809+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:40.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:46:40.820+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:40.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:41.794+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:46:41.895+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:41.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:46:41.941+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:46:41.941+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:46:42.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.257 seconds
[2024-10-28T05:47:12.786+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:12.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:47:12.792+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:12.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:13.879+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:13.918+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:13.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:47:13.967+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:13.967+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:47:14.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.332 seconds
[2024-10-28T05:47:44.424+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:44.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:47:44.429+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:44.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:45.405+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:47:45.441+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:45.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:47:45.483+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:47:45.483+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:47:45.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.498 seconds
[2024-10-28T05:48:16.154+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:48:16.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:48:16.196+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:48:16.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:48:49.251+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:48:46.871+0000] {timeout.py:68} ERROR - Process timed out, PID: 446
[2024-10-28T05:49:02.446+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:48:51.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 52, in <module>
    from .abstracts import CMySQLPrepStmt, MySQLConnectionAbstract
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 92, in <module>
    from .opentelemetry.constants import (
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/opentelemetry/constants.py", line 36, in <module>
    from opentelemetry import trace  # check api
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/trace/__init__.py", line 86, in <module>
    from opentelemetry import context as context_api
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/context/__init__.py", line 69, in <module>
    _RUNTIME_CONTEXT = _load_runtime_context()
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/context/__init__.py", line 47, in _load_runtime_context
    entry_points(  # type: ignore
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 952, in entry_points
    return EntryPoints(eps).select(**params)
           ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 950, in <genexpr>
    dist.entry_points for dist in _unique(distributions())
    ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 491, in entry_points
    return EntryPoints._from_text_for(self.read_text('entry_points.txt'), self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 328, in _from_text_for
    return cls(ep._for(dist) for ep in cls._from_text(text))
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 334, in _from_text
    for item in Sectioned.section_pairs(text or '')
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 107, in section_pairs
    @classmethod
    
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 446
[2024-10-28T05:49:03.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:49:37.224+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:49:37.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:49:37.269+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:49:37.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:49:58.881+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:49:59.859+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:49:59.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:49:59.932+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:49:59.932+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:49:59.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 22.875 seconds
[2024-10-28T05:50:30.561+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:50:30.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:50:30.575+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:50:30.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:50:31.984+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:50:32.287+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:50:32.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:50:32.556+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:50:32.553+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:50:32.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.310 seconds
[2024-10-28T05:51:03.591+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:03.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:51:03.619+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:03.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:05.534+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:05.813+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:05.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:51:05.905+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:05.905+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:51:05.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.430 seconds
[2024-10-28T05:51:36.189+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:36.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:51:36.207+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:36.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:38.784+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:51:45.306+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:45.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:51:45.626+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:51:45.625+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:51:45.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 9.620 seconds
[2024-10-28T05:52:16.736+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:16.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:52:16.745+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:16.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:17.799+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:18.284+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:18.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:52:18.397+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:18.396+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:52:18.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.743 seconds
[2024-10-28T05:52:48.642+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:48.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:52:48.670+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:48.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:52.341+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:52:52.413+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:52.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:52:52.503+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:52:52.502+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:52:52.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.953 seconds
[2024-10-28T05:53:22.738+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:22.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:53:22.743+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:22.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:23.785+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:23.955+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:23.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:53:24.031+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:24.030+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:53:24.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.355 seconds
[2024-10-28T05:53:54.810+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:54.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:53:54.818+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:54.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:55.752+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:53:55.855+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:55.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:53:55.908+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:53:55.908+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:53:55.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.167 seconds
[2024-10-28T05:54:26.399+0000] {processor.py:186} INFO - Started process (PID=520) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:54:26.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:54:26.403+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:54:26.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:54:28.061+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:54:59.950+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T05:55:34.187+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:55:34.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:55:34.200+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:55:34.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:55:35.853+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:55:36.946+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:55:36.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:55:37.068+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:55:37.068+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:55:37.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.980 seconds
[2024-10-28T05:56:07.668+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:07.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:56:07.673+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:07.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:08.748+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:08.879+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:08.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:56:08.972+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:08.972+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:56:09.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.420 seconds
[2024-10-28T05:56:39.798+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:39.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:56:39.812+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:39.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:40.932+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:56:41.033+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:41.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:56:41.077+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:56:41.077+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:56:41.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.349 seconds
[2024-10-28T05:57:11.901+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:57:11.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:57:11.911+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:57:11.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:57:15.507+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:57:40.076+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:57:40.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:57:40.231+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:57:40.231+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:57:40.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 28.424 seconds
[2024-10-28T05:58:11.061+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:11.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:58:11.069+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:11.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:12.143+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:12.267+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:12.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:58:12.316+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:12.315+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:58:12.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.332 seconds
[2024-10-28T05:58:43.178+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:43.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:58:43.254+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:43.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:45.073+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:58:45.497+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:45.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:58:45.587+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:58:45.586+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:58:45.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.611 seconds
[2024-10-28T05:59:16.471+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:16.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:59:16.476+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:16.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:19.631+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:21.715+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:21.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:59:21.831+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:21.830+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:59:21.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 5.433 seconds
[2024-10-28T05:59:52.325+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:52.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T05:59:52.330+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:52.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:53.265+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T05:59:53.389+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:53.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T05:59:53.495+0000] {logging_mixin.py:190} INFO - [2024-10-28T05:59:53.495+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T05:59:53.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.236 seconds
[2024-10-28T06:00:24.123+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:24.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:00:24.129+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:24.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:25.003+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:25.074+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:25.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:00:25.125+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:25.125+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:00:25.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.077 seconds
[2024-10-28T06:00:55.683+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:55.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:00:55.687+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:55.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:56.301+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:00:56.338+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:56.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:00:56.392+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:00:56.391+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:00:56.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.767 seconds
[2024-10-28T06:01:26.676+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:26.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:01:26.681+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:26.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:27.393+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:27.440+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:27.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:01:27.486+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:27.485+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:01:27.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.864 seconds
[2024-10-28T06:01:58.492+0000] {processor.py:186} INFO - Started process (PID=648) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:58.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:01:58.497+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:58.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:59.161+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:01:59.291+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:59.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:01:59.354+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:01:59.353+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:01:59.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.932 seconds
[2024-10-28T06:02:30.073+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:02:30.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:02:30.083+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:02:30.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:02:31.561+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:02:31.691+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:02:31.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:02:31.774+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:02:31.774+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:02:31.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.854 seconds
[2024-10-28T06:03:02.676+0000] {processor.py:186} INFO - Started process (PID=668) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:02.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:03:02.683+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:02.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:04.097+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:04.217+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:04.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:03:04.377+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:04.377+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:03:04.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.821 seconds
[2024-10-28T06:03:35.055+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:35.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:03:35.062+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:35.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:36.031+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:03:36.088+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:36.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:03:36.168+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:03:36.167+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:03:36.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.180 seconds
[2024-10-28T06:04:06.836+0000] {processor.py:186} INFO - Started process (PID=688) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:04:06.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:04:06.843+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:04:06.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:04:07.819+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:04:07.883+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:04:07.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:04:07.995+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:04:07.994+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:04:08.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.256 seconds
[2024-10-28T06:04:38.744+0000] {processor.py:186} INFO - Started process (PID=697) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:04:38.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:04:38.792+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:04:38.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:04:45.466+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:05:17.738+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 721, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T06:06:10.507+0000] {processor.py:186} INFO - Started process (PID=704) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:10.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:06:10.533+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:10.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:13.575+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:19.026+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:19.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:06:19.132+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:19.132+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:06:19.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 8.756 seconds
[2024-10-28T06:06:49.557+0000] {processor.py:186} INFO - Started process (PID=713) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:49.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:06:49.563+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:49.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:51.184+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:06:51.356+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:51.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:06:51.463+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:06:51.462+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:06:51.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.112 seconds
[2024-10-28T06:07:22.108+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:22.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:07:22.118+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:22.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:23.918+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:24.188+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:24.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:07:24.347+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:24.338+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:07:24.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.437 seconds
[2024-10-28T06:07:54.932+0000] {processor.py:186} INFO - Started process (PID=732) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:54.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:07:54.943+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:54.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:57.065+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:07:57.295+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:57.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:07:57.431+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:07:57.430+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:07:57.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.621 seconds
[2024-10-28T06:08:28.455+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T06:08:28.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T06:08:28.465+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:08:28.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T06:08:30.038+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T06:08:30.113+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:08:30.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T06:08:30.210+0000] {logging_mixin.py:190} INFO - [2024-10-28T06:08:30.209+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T06:08:30.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.836 seconds
[2024-10-28T13:22:34.457+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:22:34.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:22:34.589+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:22:34.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:22:40.327+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:22:40.587+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:22:40.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:22:42.613+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:22:42.612+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:22:43.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 8.607 seconds
[2024-10-28T13:23:13.638+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:23:13.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:23:13.823+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:23:13.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:23:57.242+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:23:57.241+0000] {timeout.py:68} ERROR - Process timed out, PID: 57
[2024-10-28T13:23:57.261+0000] {logging_mixin.py:190} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f3b4a1a2f20>
[2024-10-28T13:23:57.263+0000] {logging_mixin.py:190} WARNING - Traceback (most recent call last):
[2024-10-28T13:23:57.265+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/weakref.py", line 369, in remove
[2024-10-28T13:23:57.266+0000] {logging_mixin.py:190} WARNING -     def remove(k, selfref=ref(self)):
[2024-10-28T13:23:57.266+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2024-10-28T13:23:57.267+0000] {logging_mixin.py:190} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2024-10-28T13:23:57.272+0000] {logging_mixin.py:190} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 57
[2024-10-28T13:23:57.444+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:23:59.216+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:23:59.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:23:59.369+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:23:59.367+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:23:59.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 45.917 seconds
[2024-10-28T13:24:29.874+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:24:29.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:24:29.906+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:24:29.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:24:44.796+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:24:44.837+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:24:44.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:24:44.889+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:24:44.888+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:24:44.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 15.106 seconds
[2024-10-28T13:25:15.412+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:15.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:25:15.428+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:15.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:16.358+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:16.409+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:16.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:25:16.465+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:16.464+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:25:16.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.133 seconds
[2024-10-28T13:25:49.408+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:49.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:25:49.470+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:49.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:57.409+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:25:57.518+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:57.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:25:57.583+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:25:57.583+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:25:57.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 8.864 seconds
[2024-10-28T13:26:29.297+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:26:29.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:26:29.345+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:26:29.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:26:48.340+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:26:48.409+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:26:48.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:26:48.613+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:26:48.612+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:26:49.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 20.266 seconds
[2024-10-28T13:27:21.312+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:27:21.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:27:21.466+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:27:21.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:36:49.093+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:36:39.871+0000] {timeout.py:68} ERROR - Process timed out, PID: 123
[2024-10-28T13:36:57.579+0000] {logging_mixin.py:190} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f3b4a1a2f20>
[2024-10-28T13:37:17.986+0000] {logging_mixin.py:190} WARNING - Traceback (most recent call last):
[2024-10-28T13:45:27.125+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:45:27.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:45:27.140+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:45:27.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:45:30.753+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:45:33.234+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:45:33.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:45:34.700+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:45:34.698+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:45:34.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 7.663 seconds
[2024-10-28T13:46:43.829+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:46:43.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:46:43.834+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:46:43.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:46:44.846+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:46:45.041+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:46:45.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:46:45.123+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:46:45.122+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:46:45.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.444 seconds
[2024-10-28T13:47:15.447+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:15.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:47:15.464+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:15.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:16.934+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:16.980+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:16.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:47:17.021+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:17.020+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:47:17.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.617 seconds
[2024-10-28T13:47:47.966+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:47.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:47:47.976+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:47.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:49.390+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:47:49.424+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:49.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:47:49.460+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:47:49.459+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:47:49.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.623 seconds
[2024-10-28T13:48:19.858+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:19.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:48:20.201+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:19.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:22.872+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:22.908+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:22.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:48:22.952+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:22.951+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:48:23.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.339 seconds
[2024-10-28T13:48:53.716+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:53.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:48:53.721+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:53.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:54.490+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:48:54.521+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:54.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:48:54.561+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:48:54.561+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:48:54.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.017 seconds
[2024-10-28T13:49:25.277+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:25.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:49:25.283+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:25.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:26.044+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:26.102+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:26.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:49:26.167+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:26.167+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:49:26.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.110 seconds
[2024-10-28T13:49:56.474+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:56.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:49:56.480+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:56.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:56.980+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:49:57.018+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:57.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:49:57.052+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:49:57.052+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:49:57.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.618 seconds
[2024-10-28T13:50:27.604+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:27.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:50:27.614+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:27.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:28.296+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:28.331+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:28.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:50:28.371+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:28.370+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:50:28.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.814 seconds
[2024-10-28T13:50:59.501+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:59.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:50:59.507+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:59.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:59.857+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:50:59.901+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:59.900+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:50:59.956+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:50:59.955+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:51:00.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.637 seconds
[2024-10-28T13:51:31.022+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:51:31.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:51:31.029+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:51:31.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:51:32.088+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:51:32.184+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:51:32.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:51:32.275+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:51:32.275+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:51:32.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.538 seconds
[2024-10-28T13:52:02.944+0000] {processor.py:186} INFO - Started process (PID=133) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:02.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:52:02.951+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:02.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:03.720+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:03.809+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:03.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:52:03.960+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:03.959+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:52:04.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.375 seconds
[2024-10-28T13:52:34.719+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:34.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:52:34.727+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:34.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:35.456+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:52:35.547+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:35.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:52:35.707+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:52:35.706+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:52:35.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.053 seconds
[2024-10-28T13:53:05.920+0000] {processor.py:186} INFO - Started process (PID=153) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:05.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:53:05.926+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:05.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:06.263+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:06.302+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:06.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:53:06.348+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:06.347+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:53:06.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.477 seconds
[2024-10-28T13:53:36.969+0000] {processor.py:186} INFO - Started process (PID=163) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:36.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:53:36.986+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:36.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:37.677+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:53:37.730+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:37.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:53:37.787+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:53:37.787+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:53:37.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.883 seconds
[2024-10-28T13:54:08.118+0000] {processor.py:186} INFO - Started process (PID=173) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:08.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:54:08.133+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:08.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:08.724+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:08.840+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:08.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:54:08.989+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:08.988+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:54:09.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.042 seconds
[2024-10-28T13:54:39.658+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:39.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:54:39.666+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:39.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:40.586+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:54:40.705+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:40.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:54:40.886+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:54:40.886+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:54:41.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.387 seconds
[2024-10-28T13:55:13.819+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:13.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:55:13.837+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:13.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:14.548+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:14.711+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:14.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:55:14.871+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:14.871+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:55:15.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.314 seconds
[2024-10-28T13:55:45.859+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:45.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:55:45.867+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:45.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:46.194+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:55:46.242+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:46.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:55:46.292+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:55:46.292+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:55:46.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.511 seconds
[2024-10-28T13:56:16.472+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:16.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:56:16.480+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:16.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:17.117+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:17.201+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:17.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:56:17.264+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:17.263+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:56:17.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.858 seconds
[2024-10-28T13:56:48.013+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:48.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:56:48.022+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:48.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:49.134+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:56:49.287+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:49.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:56:49.450+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:56:49.449+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:56:49.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.576 seconds
[2024-10-28T13:57:19.763+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:19.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:57:19.769+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:19.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:20.004+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:20.045+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:20.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:57:20.080+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:20.080+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:57:20.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.364 seconds
[2024-10-28T13:57:50.223+0000] {processor.py:186} INFO - Started process (PID=247) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:50.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:57:50.227+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:50.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:50.465+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:57:50.497+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:50.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:57:50.532+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:57:50.531+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:57:50.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.350 seconds
[2024-10-28T13:58:21.186+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:21.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:58:21.190+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:21.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:21.441+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:21.474+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:21.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:58:21.511+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:21.511+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:58:21.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.372 seconds
[2024-10-28T13:58:52.101+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:52.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:58:52.106+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:52.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:52.367+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:58:52.403+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:52.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:58:52.442+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:58:52.442+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:58:52.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.382 seconds
[2024-10-28T13:59:22.749+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:22.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:59:22.755+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:22.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:23.105+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:23.169+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:23.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:59:23.323+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:23.323+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:59:23.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.650 seconds
[2024-10-28T13:59:53.533+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:53.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T13:59:53.539+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:53.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:53.815+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T13:59:53.849+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:53.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T13:59:53.885+0000] {logging_mixin.py:190} INFO - [2024-10-28T13:59:53.884+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T13:59:53.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.394 seconds
[2024-10-28T14:00:24.201+0000] {processor.py:186} INFO - Started process (PID=299) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:24.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:00:24.205+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:24.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:24.436+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:24.468+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:24.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:00:24.502+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:24.502+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:00:24.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.341 seconds
[2024-10-28T14:00:55.107+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:55.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:00:55.112+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:55.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:55.401+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:00:55.465+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:55.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:00:55.534+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:00:55.533+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:00:55.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.507 seconds
[2024-10-28T14:01:25.765+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:25.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:01:25.773+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:25.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:26.098+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:26.129+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:26.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:01:26.172+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:26.171+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:01:26.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.453 seconds
[2024-10-28T14:01:56.486+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:56.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:01:56.499+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:56.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:56.830+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:01:56.889+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:56.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:01:56.936+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:01:56.935+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:01:56.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.499 seconds
[2024-10-28T14:02:27.575+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:27.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:02:27.581+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:27.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:27.931+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:27.994+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:27.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:02:28.034+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:28.034+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:02:28.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.500 seconds
[2024-10-28T14:02:58.633+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:58.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:02:58.682+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:58.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:59.485+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:02:59.623+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:59.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:02:59.819+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:02:59.819+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:03:00.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.493 seconds
[2024-10-28T14:03:30.849+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:03:30.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:03:30.854+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:03:30.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:03:31.117+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:03:31.148+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:03:31.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:03:31.181+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:03:31.180+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:03:31.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.377 seconds
[2024-10-28T14:04:01.504+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:01.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:04:01.510+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:01.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:01.795+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:01.828+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:01.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:04:01.864+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:01.863+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:04:01.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.405 seconds
[2024-10-28T14:04:31.982+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:31.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:04:31.987+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:31.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:32.249+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:04:32.280+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:32.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:04:32.315+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:04:32.314+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:04:32.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.778 seconds
[2024-10-28T14:05:03.233+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:03.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:05:03.238+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:03.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:03.454+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:03.487+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:03.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:05:03.520+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:03.520+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:05:03.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.325 seconds
[2024-10-28T14:05:33.995+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:33.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:05:33.999+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:33.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:34.210+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:05:34.240+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:34.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:05:34.272+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:05:34.272+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:05:34.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.317 seconds
[2024-10-28T14:06:04.502+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:04.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:06:04.508+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:04.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:04.771+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:04.806+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:04.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:06:04.852+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:04.852+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:06:04.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.402 seconds
[2024-10-28T14:06:35.126+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:35.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:06:35.131+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:35.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:35.414+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:06:35.450+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:35.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:06:35.492+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:06:35.491+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:06:35.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.416 seconds
[2024-10-28T14:07:06.508+0000] {processor.py:186} INFO - Started process (PID=427) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:06.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:07:06.537+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:06.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:07.056+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:07.107+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:07.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:07:07.176+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:07.176+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:07:07.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.730 seconds
[2024-10-28T14:07:37.957+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:37.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:07:37.964+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:37.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:38.453+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:07:38.504+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:38.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:07:38.562+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:07:38.562+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:07:38.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.660 seconds
[2024-10-28T14:08:09.152+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:09.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:08:09.159+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:09.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:09.421+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:09.461+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:09.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:08:09.504+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:09.503+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:08:09.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.400 seconds
[2024-10-28T14:08:40.271+0000] {processor.py:186} INFO - Started process (PID=457) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:40.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:08:40.277+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:40.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:40.525+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:08:40.559+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:40.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:08:40.594+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:08:40.593+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:08:40.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.364 seconds
[2024-10-28T14:09:11.015+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:11.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:09:11.022+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:11.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:11.543+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:11.588+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:11.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:09:11.632+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:11.632+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:09:11.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.668 seconds
[2024-10-28T14:09:41.952+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:42.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:09:42.144+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:42.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:42.915+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:09:42.971+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:42.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:09:43.047+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:09:43.047+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:09:43.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.171 seconds
[2024-10-28T14:10:13.413+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:10:13.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:10:13.421+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:10:13.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:10:14.186+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:10:14.310+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:10:14.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:10:14.359+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:10:14.358+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:10:14.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.009 seconds
[2024-10-28T14:13:55.425+0000] {processor.py:186} INFO - Started process (PID=499) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:13:55.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:13:55.444+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:13:55.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:14:01.497+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:14:04.704+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:14:04.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:14:04.802+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:14:04.801+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:14:04.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 9.677 seconds
[2024-10-28T14:14:35.764+0000] {processor.py:186} INFO - Started process (PID=509) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:14:35.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:14:35.768+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:14:35.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:14:36.500+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:14:36.551+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:14:36.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:14:36.603+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:14:36.603+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:14:36.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.923 seconds
[2024-10-28T14:15:07.301+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:07.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:15:07.305+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:07.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:08.196+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:08.235+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:08.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:15:08.274+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:08.274+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:15:08.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.022 seconds
[2024-10-28T14:15:39.316+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:39.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:15:39.321+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:39.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:40.319+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:15:40.360+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:40.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:15:40.413+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:15:40.412+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:15:40.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.144 seconds
[2024-10-28T14:16:10.846+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:10.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:16:10.849+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:10.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:11.445+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:11.512+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:11.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:16:11.557+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:11.557+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:16:11.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.054 seconds
[2024-10-28T14:16:42.543+0000] {processor.py:186} INFO - Started process (PID=553) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:42.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:16:42.547+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:42.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:43.085+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:16:43.132+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:43.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:16:43.171+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:16:43.171+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:16:43.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.674 seconds
[2024-10-28T14:17:13.338+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:13.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:17:13.342+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:13.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:13.736+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:13.776+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:13.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:17:13.820+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:13.819+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:17:13.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.539 seconds
[2024-10-28T14:17:44.146+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:44.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:17:44.150+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:44.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:44.838+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:17:44.883+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:44.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:17:44.934+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:17:44.934+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:17:44.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.840 seconds
[2024-10-28T14:18:15.428+0000] {processor.py:186} INFO - Started process (PID=593) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:15.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:18:15.432+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:15.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:15.895+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:15.932+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:15.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:18:15.998+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:15.997+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:18:16.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.625 seconds
[2024-10-28T14:18:46.268+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:46.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:18:46.271+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:46.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:46.842+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:18:46.938+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:46.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:18:46.986+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:18:46.985+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:18:47.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.767 seconds
[2024-10-28T14:19:17.742+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:17.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:19:17.746+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:17.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:18.378+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:18.476+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:18.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:19:18.558+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:18.558+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:19:18.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.865 seconds
[2024-10-28T14:19:49.014+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:49.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:19:49.020+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:49.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:49.707+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:19:49.742+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:49.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:19:49.780+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:19:49.780+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:19:49.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.816 seconds
[2024-10-28T14:20:20.013+0000] {processor.py:186} INFO - Started process (PID=638) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:20:20.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:20:20.020+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:20:20.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:20:20.611+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:20:20.654+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:20:20.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:20:20.699+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:20:20.698+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:20:20.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.753 seconds
[2024-10-28T14:24:26.792+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:24:26.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:24:26.797+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:24:26.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:24:29.363+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:24:29.822+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:24:29.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:24:32.772+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:24:32.769+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:24:32.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 6.040 seconds
[2024-10-28T14:25:03.169+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:03.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:25:03.175+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:03.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:06.508+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:06.562+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:06.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:25:06.622+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:06.621+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:25:06.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.533 seconds
[2024-10-28T14:25:37.338+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:37.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:25:37.406+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:37.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:40.725+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:25:40.752+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:40.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:25:40.793+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:25:40.793+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:25:41.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.791 seconds
[2024-10-28T14:26:11.716+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:11.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:26:11.723+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:11.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:13.749+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:13.804+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:13.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:26:13.872+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:13.871+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:26:13.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.254 seconds
[2024-10-28T14:26:44.278+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:44.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:26:44.283+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:44.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:45.379+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:26:45.416+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:45.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:26:45.447+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:26:45.447+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:26:45.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.209 seconds
[2024-10-28T14:27:15.710+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:15.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:27:15.716+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:15.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:16.364+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:16.483+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:16.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:27:16.613+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:16.612+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:27:16.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.042 seconds
[2024-10-28T14:27:47.283+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:47.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:27:47.289+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:47.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:48.224+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:27:48.258+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:48.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:27:48.301+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:27:48.301+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:27:48.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.058 seconds
[2024-10-28T14:28:18.766+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:18.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:28:18.782+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:18.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:22.696+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:23.012+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:23.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:28:23.076+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:23.076+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:28:23.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 4.458 seconds
[2024-10-28T14:28:53.282+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:53.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:28:53.288+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:53.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:54.537+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:28:54.684+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:54.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:28:54.740+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:28:54.740+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:28:54.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.510 seconds
[2024-10-28T14:29:25.176+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:25.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:29:25.221+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:25.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:26.414+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:26.444+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:26.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:29:26.478+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:26.477+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:29:26.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.354 seconds
[2024-10-28T14:29:57.453+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:57.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:29:57.464+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:57.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:58.382+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:29:58.415+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:58.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:29:58.464+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:29:58.464+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:29:58.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.172 seconds
[2024-10-28T14:30:29.206+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:30:29.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:30:29.214+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:30:29.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:30:30.503+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:30:30.619+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:30:30.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:30:30.729+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:30:30.728+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:30:30.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.626 seconds
[2024-10-28T14:31:01.363+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:01.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:31:01.379+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:01.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:02.876+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:02.976+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:02.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:31:03.022+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:03.022+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:31:03.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.740 seconds
[2024-10-28T14:31:33.384+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:33.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:31:33.390+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:33.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:34.196+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:31:34.270+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:34.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:31:34.310+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:31:34.310+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:31:34.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.982 seconds
[2024-10-28T14:32:05.369+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:05.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:32:05.375+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:05.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:07.322+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:07.438+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:07.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:32:07.490+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:07.490+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:32:07.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.182 seconds
[2024-10-28T14:32:37.861+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:37.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:32:37.871+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:37.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:38.953+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:32:39.223+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:39.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:32:39.284+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:32:39.283+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:32:39.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.484 seconds
[2024-10-28T14:33:09.442+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:09.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:33:09.446+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:09.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:12.109+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:13.131+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:13.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:33:13.187+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:13.187+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:33:13.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 3.834 seconds
[2024-10-28T14:33:43.950+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:43.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:33:43.956+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:43.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:45.585+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:33:45.621+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:45.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:33:45.685+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:33:45.684+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:33:45.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.783 seconds
[2024-10-28T14:34:15.835+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:15.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:34:15.854+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:15.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:16.797+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:16.832+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:16.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:34:16.882+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:16.882+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:34:16.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.114 seconds
[2024-10-28T14:34:47.201+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:47.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:34:47.218+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:47.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:49.761+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:34:49.844+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:49.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T14:34:49.937+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:34:49.936+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T14:34:50.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.835 seconds
[2024-10-28T14:35:21.657+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T14:35:21.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T14:35:21.733+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:35:21.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T14:35:59.580+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:35:57.041+0000] {timeout.py:68} ERROR - Process timed out, PID: 260
[2024-10-28T14:37:10.185+0000] {logging_mixin.py:190} INFO - [2024-10-28T14:36:01.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/pg_my.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 856, in read_text
    return self._path.joinpath(filename).read_text(encoding='utf-8')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/pathlib.py", line 1027, in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/pathlib.py", line 1013, in open
    return io.open(self, mode, buffering, encoding, errors, newline)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/airflow/.local/lib/python3.12/site-packages/typing_extensions-4.12.2.dist-info/entry_points.txt'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pg_my.py", line 5, in <module>
    import mysql.connector  # Import untuk MySQL
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/__init__.py", line 32, in <module>
    from .connection_cext import CMySQLConnection
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 52, in <module>
    from .abstracts import CMySQLPrepStmt, MySQLConnectionAbstract
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 92, in <module>
    from .opentelemetry.constants import (
  File "/home/airflow/.local/lib/python3.12/site-packages/mysql/connector/opentelemetry/constants.py", line 36, in <module>
    from opentelemetry import trace  # check api
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/trace/__init__.py", line 86, in <module>
    from opentelemetry import context as context_api
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/context/__init__.py", line 69, in <module>
    _RUNTIME_CONTEXT = _load_runtime_context()
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/opentelemetry/context/__init__.py", line 47, in _load_runtime_context
    entry_points(  # type: ignore
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 952, in entry_points
    return EntryPoints(eps).select(**params)
           ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 950, in <genexpr>
    dist.entry_points for dist in _unique(distributions())
    ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 491, in entry_points
    return EntryPoints._from_text_for(self.read_text('entry_points.txt'), self)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/importlib_metadata/__init__.py", line 849, in read_text
    with suppress(
         ^^^^^^^^^
  File "/usr/local/lib/python3.12/contextlib.py", line 446, in __exit__
    def __exit__(self, exctype, excinst, exctb):
    
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/pg_my.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 260
[2024-10-28T14:38:30.231+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T14:40:24.762+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 928, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 648, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(ParseImportError.filename).all()]
                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
         ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-10-28T15:01:31.410+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:01:31.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:01:31.505+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:01:31.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:01:55.977+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:01:55.976+0000] {process_utils.py:266} INFO - Waiting up to 5 seconds for processes to exit...
[2024-10-28T15:01:55.985+0000] {logging_mixin.py:190} WARNING - Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f0e412eaf20>
[2024-10-28T15:01:55.986+0000] {logging_mixin.py:190} WARNING - Traceback (most recent call last):
[2024-10-28T15:01:55.987+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/weakref.py", line 369, in remove
[2024-10-28T15:01:55.988+0000] {logging_mixin.py:190} WARNING -     def remove(k, selfref=ref(self)):
[2024-10-28T15:01:55.989+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/manager.py", line 466, in _exit_gracefully
[2024-10-28T15:01:55.990+0000] {logging_mixin.py:190} WARNING -     self.log.debug("Current Stacktrace is: %s", "\n".join(map(str, inspect.stack())))
[2024-10-28T15:01:56.000+0000] {logging_mixin.py:190} WARNING -                                                                    ^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.002+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1777, in stack
[2024-10-28T15:01:56.006+0000] {logging_mixin.py:190} WARNING -     return getouterframes(sys._getframe(1), context)
[2024-10-28T15:01:56.007+0000] {logging_mixin.py:190} WARNING -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.009+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1752, in getouterframes
[2024-10-28T15:01:56.012+0000] {logging_mixin.py:190} WARNING -     traceback_info = getframeinfo(frame, context)
[2024-10-28T15:01:56.015+0000] {logging_mixin.py:190} WARNING -                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.017+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1710, in getframeinfo
[2024-10-28T15:01:56.025+0000] {logging_mixin.py:190} WARNING -     filename = getsourcefile(frame) or getfile(frame)
[2024-10-28T15:01:56.034+0000] {logging_mixin.py:190} WARNING -                ^^^^^^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.038+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 970, in getsourcefile
[2024-10-28T15:01:56.043+0000] {logging_mixin.py:190} WARNING -     module = getmodule(object, filename)
[2024-10-28T15:01:56.047+0000] {logging_mixin.py:190} WARNING -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.048+0000] {logging_mixin.py:190} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1007, in getmodule
[2024-10-28T15:01:56.051+0000] {logging_mixin.py:190} WARNING -     if ismodule(module) and hasattr(module, '__file__'):
[2024-10-28T15:01:56.052+0000] {logging_mixin.py:190} WARNING -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-10-28T15:01:56.052+0000] {logging_mixin.py:190} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/manager.py", line 470, in _exit_gracefully
[2024-10-28T15:01:56.053+0000] {logging_mixin.py:190} WARNING -     sys.exit(os.EX_OK)
[2024-10-28T15:01:56.054+0000] {logging_mixin.py:190} WARNING - SystemExit: 0
[2024-10-28T15:01:57.911+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:01:57.910+0000] {process_utils.py:266} INFO - Waiting up to 5 seconds for processes to exit...
[2024-10-28T15:03:16.279+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:03:16.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:03:16.302+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:03:16.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:03:18.233+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:03:18.232+0000] {process_utils.py:266} INFO - Waiting up to 5 seconds for processes to exit...
[2024-10-28T15:04:04.459+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:04.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:04:04.530+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:04.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:06.801+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:07.001+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:07.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:04:07.070+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:07.069+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:04:07.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.806 seconds
[2024-10-28T15:04:37.607+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:37.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:04:37.613+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:37.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:38.555+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:04:38.604+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:38.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:04:38.641+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:04:38.641+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:04:38.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.133 seconds
[2024-10-28T15:05:09.904+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:09.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:05:09.911+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:09.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:11.357+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:11.386+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:11.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:05:11.417+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:11.417+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:05:11.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.553 seconds
[2024-10-28T15:05:42.258+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:42.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:05:42.270+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:42.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:42.818+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:05:42.848+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:42.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:05:42.885+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:05:42.885+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:05:42.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.693 seconds
[2024-10-28T15:06:13.821+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:13.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:06:13.826+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:13.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:14.384+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:14.416+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:14.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:06:14.453+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:14.453+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:06:14.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.740 seconds
[2024-10-28T15:06:44.872+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:44.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:06:44.878+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:44.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:45.370+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:06:45.402+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:45.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:06:45.440+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:06:45.439+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:06:45.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.615 seconds
[2024-10-28T15:07:16.026+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:16.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:07:16.033+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:16.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:17.655+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:17.824+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:17.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:07:17.976+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:17.976+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:07:18.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 2.089 seconds
[2024-10-28T15:07:48.781+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:48.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:07:48.788+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:48.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:49.480+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:07:49.526+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:49.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:07:49.562+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:07:49.561+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:07:49.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.829 seconds
[2024-10-28T15:08:19.833+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:19.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:08:19.846+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:19.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:20.124+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:20.154+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:20.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:08:20.189+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:20.188+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:08:20.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.583 seconds
[2024-10-28T15:08:50.868+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:50.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:08:50.875+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:50.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:51.165+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:08:51.196+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:51.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:08:51.234+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:08:51.234+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:08:51.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.480 seconds
[2024-10-28T15:09:22.044+0000] {processor.py:186} INFO - Started process (PID=143) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:22.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:09:22.050+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:22.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:22.346+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:22.380+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:22.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:09:22.417+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:22.416+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:09:22.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.413 seconds
[2024-10-28T15:09:52.902+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:52.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:09:52.967+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:52.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:53.530+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:09:53.563+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:53.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:09:53.603+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:09:53.603+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:09:53.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.802 seconds
[2024-10-28T15:10:23.950+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:23.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:10:23.957+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:23.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:24.883+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:25.002+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:25.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:10:25.178+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:25.178+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:10:25.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.352 seconds
[2024-10-28T15:10:56.082+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:56.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:10:56.089+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:56.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:56.341+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:10:56.382+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:56.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:10:56.423+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:10:56.422+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:10:56.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.803 seconds
[2024-10-28T15:11:27.569+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:27.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:11:27.577+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:27.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:28.073+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:28.115+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:28.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:11:28.172+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:28.172+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:11:28.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.672 seconds
[2024-10-28T15:11:58.301+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:58.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:11:58.308+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:58.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:58.609+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:11:58.643+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:58.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:11:58.678+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:11:58.678+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:11:58.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.436 seconds
[2024-10-28T15:12:28.952+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:12:28.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:12:28.969+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:12:28.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:12:29.612+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:12:29.678+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:12:29.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:12:29.733+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:12:29.733+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:12:29.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.867 seconds
[2024-10-28T15:12:59.949+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:12:59.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:12:59.955+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:12:59.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:13:00.272+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:13:00.308+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:13:00.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:13:00.343+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:13:00.342+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:13:00.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.440 seconds
[2024-10-28T15:13:30.646+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:13:30.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:13:30.662+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:13:30.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:13:31.201+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:13:31.301+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:13:31.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:13:31.384+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:13:31.384+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:13:31.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.797 seconds
[2024-10-28T15:14:01.927+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:01.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:14:01.933+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:01.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:02.226+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:02.273+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:02.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:14:02.332+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:02.332+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:14:02.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.464 seconds
[2024-10-28T15:14:33.070+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:33.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:14:33.075+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:33.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:33.348+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:14:33.407+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:33.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:14:33.450+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:14:33.450+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:14:33.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.422 seconds
[2024-10-28T15:15:03.724+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:03.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:15:03.729+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:03.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:03.964+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:04.010+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:04.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:15:04.069+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:04.068+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:15:04.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.398 seconds
[2024-10-28T15:15:34.248+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:34.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:15:34.253+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:34.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:34.530+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:15:34.563+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:34.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:15:34.598+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:15:34.598+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:15:34.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.399 seconds
[2024-10-28T15:16:05.287+0000] {processor.py:186} INFO - Started process (PID=294) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:05.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:16:05.293+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:05.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:05.584+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:05.618+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:05.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:16:05.660+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:05.660+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:16:05.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.426 seconds
[2024-10-28T15:16:35.862+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:35.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:16:35.868+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:35.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:36.087+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:16:36.118+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:36.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:16:36.152+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:16:36.152+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:16:36.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.329 seconds
[2024-10-28T15:17:07.320+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:07.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:17:07.341+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:07.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:08.420+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:08.574+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:08.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:17:08.815+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:08.815+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:17:09.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.819 seconds
[2024-10-28T15:17:39.401+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:39.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:17:39.408+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:39.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:39.730+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:17:39.775+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:39.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:17:39.814+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:17:39.813+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:17:40.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.758 seconds
[2024-10-28T15:18:10.983+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:10.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:18:10.988+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:10.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:11.205+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:11.239+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:11.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:18:11.272+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:11.272+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:18:11.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.331 seconds
[2024-10-28T15:18:41.885+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:41.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:18:41.890+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:41.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:42.146+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:18:42.179+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:42.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:18:42.221+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:18:42.220+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:18:42.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.425 seconds
[2024-10-28T15:19:13.177+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:13.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:19:13.182+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:13.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:13.499+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:13.544+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:13.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:19:13.601+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:13.598+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:19:13.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.478 seconds
[2024-10-28T15:19:44.263+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:44.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:19:44.269+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:44.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:44.510+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:19:44.541+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:44.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:19:44.574+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:19:44.573+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:19:44.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.365 seconds
[2024-10-28T15:20:15.490+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:15.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:20:15.497+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:15.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:15.774+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:15.841+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:15.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:20:15.883+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:15.882+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:20:15.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.445 seconds
[2024-10-28T15:20:46.739+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:46.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:20:46.745+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:46.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:47.008+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:20:47.042+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:47.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:20:47.080+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:20:47.080+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:20:47.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.383 seconds
[2024-10-28T15:21:17.270+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:17.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:21:17.275+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:17.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:18.066+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:18.200+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:18.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:21:18.286+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:18.286+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:21:18.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.094 seconds
[2024-10-28T15:21:49.101+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:49.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:21:49.106+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:49.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:49.326+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:21:49.359+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:49.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:21:49.392+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:21:49.392+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:21:49.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.331 seconds
[2024-10-28T15:22:19.836+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:19.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:22:19.857+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:19.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:20.504+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:20.621+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:20.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:22:20.764+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:20.764+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:22:20.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 1.098 seconds
[2024-10-28T15:22:51.599+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:51.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/pg_my.py for tasks to queue
[2024-10-28T15:22:51.605+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:51.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:51.844+0000] {processor.py:925} INFO - DAG(s) 'postgres_to_mysql_etl' retrieved from /opt/airflow/dags/pg_my.py
[2024-10-28T15:22:51.874+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:51.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-28T15:22:51.936+0000] {logging_mixin.py:190} INFO - [2024-10-28T15:22:51.936+0000] {dag.py:4180} INFO - Setting next_dagrun for postgres_to_mysql_etl to 2024-10-28 00:00:00+00:00, run_after=2024-10-29 00:00:00+00:00
[2024-10-28T15:22:51.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/pg_my.py took 0.395 seconds
